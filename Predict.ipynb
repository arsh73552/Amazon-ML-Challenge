{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "      <td>artzfolio tulip flowers blackout curtain door ...</td>\n",
       "      <td>[[ 0.24486599  0.09132601  0.12729792  0.01665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "      <td>marks spencer girls pyjama sets t862561cnavy m...</td>\n",
       "      <td>[[ 0.12145305  0.06881733  0.02220269  0.00592...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "      <td>priknik horn red electric air horn compressor ...</td>\n",
       "      <td>[[ 0.03937757  0.08054779  0.1644971  -0.12261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "      <td>alishah womens cotton ankle length leggings co...</td>\n",
       "      <td>[[ 0.21314571  0.09550028  0.01377743 -0.02590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6112</td>\n",
       "      <td>598.424000</td>\n",
       "      <td>united empire loyalists chronicle great migrat...</td>\n",
       "      <td>[[ 0.07313064  0.02169267 -0.10552848  0.11775...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_TYPE_ID  PRODUCT_LENGTH   \n",
       "0             1650     2125.980000  \\\n",
       "1             2755      393.700000   \n",
       "2             7537      748.031495   \n",
       "3             2996      787.401574   \n",
       "4             6112      598.424000   \n",
       "\n",
       "                                                TEXT   \n",
       "0  artzfolio tulip flowers blackout curtain door ...  \\\n",
       "1  marks spencer girls pyjama sets t862561cnavy m...   \n",
       "2  priknik horn red electric air horn compressor ...   \n",
       "3  alishah womens cotton ankle length leggings co...   \n",
       "4  united empire loyalists chronicle great migrat...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [[ 0.24486599  0.09132601  0.12729792  0.01665...  \n",
       "1  [[ 0.12145305  0.06881733  0.02220269  0.00592...  \n",
       "2  [[ 0.03937757  0.08054779  0.1644971  -0.12261...  \n",
       "3  [[ 0.21314571  0.09550028  0.01377743 -0.02590...  \n",
       "4  [[ 0.07313064  0.02169267 -0.10552848  0.11775...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "data = pd.read_csv(\"word2vec.csv\")\n",
    "data = data.fillna(\"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[ 0.24486599  0.09132601  0.12729792  0.01665498 -0.04266906 -0.02752393\\n   0.04395749  0.0552298   0.01799644 -0.131849   -0.08165585 -0.04776286\\n  -0.158705   -0.09594734  0.03506118  0.05094731  0.02694449  0.00624992\\n  -0.0498466  -0.06658363  0.02969561  0.13801886 -0.18002258 -0.09880821\\n  -0.11437636  0.05922138 -0.04789598  0.16742549  0.15893989  0.29970212\\n  -0.12233958 -0.11272874 -0.12335229 -0.09279434  0.01145658  0.08247568\\n   0.09797681  0.01688097 -0.00224198 -0.11139964 -0.04053711 -0.10545407\\n   0.06608243  0.05192966  0.03598407  0.04658067 -0.01379358 -0.0969209\\n  -0.14873363  0.06211954  0.10641119 -0.00880902  0.12594728  0.00325343\\n  -0.00383921  0.09831329 -0.08108894  0.08207243  0.03107267  0.09872813\\n  -0.02845263 -0.01513546 -0.13255188  0.13859841 -0.07904432  0.06826977\\n   0.10151197 -0.00693005  0.10439347  0.10852824 -0.01616291 -0.07489225\\n   0.11050934 -0.0813156   0.10137352  0.06234654  0.18863145 -0.06374631\\n   0.05986893  0.10759768  0.08522029  0.04486798  0.14273083 -0.03315911\\n   0.0695944   0.08550626  0.0746282  -0.06087543  0.0939651  -0.30088589\\n   0.08473502  0.03522529  0.0769323   0.1838968   0.06171026  0.15270018\\n   0.04126845  0.04174056  0.01596737  0.06698156]]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vectors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TEXT'] = data['TITLE'] + ' ' + data['DESCRIPTION'] + ' ' + data['BULLET_POINTS']\n",
    "data.drop('TITLE', axis=1, inplace=True)\n",
    "data.drop('DESCRIPTION', axis=1, inplace=True)\n",
    "data.drop('BULLET_POINTS', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('preprocessed2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12907\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "      <td>artzfolio tulip flowers blackout curtain door ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "      <td>marks spencer girls pyjama sets t862561cnavy m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "      <td>priknik horn red electric air horn compressor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "      <td>alishah womens cotton ankle length leggings co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6112</td>\n",
       "      <td>598.424000</td>\n",
       "      <td>united empire loyalists chronicle great migrat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_TYPE_ID  PRODUCT_LENGTH   \n",
       "0             1650     2125.980000  \\\n",
       "1             2755      393.700000   \n",
       "2             7537      748.031495   \n",
       "3             2996      787.401574   \n",
       "4             6112      598.424000   \n",
       "\n",
       "                                                TEXT  \n",
       "0  artzfolio tulip flowers blackout curtain door ...  \n",
       "1  marks spencer girls pyjama sets t862561cnavy m...  \n",
       "2  priknik horn red electric air horn compressor ...  \n",
       "3  alishah womens cotton ankle length leggings co...  \n",
       "4  united empire loyalists chronicle great migrat...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data['PRODUCT_TYPE_ID'].unique()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['DESCRIPTION', 'TITLE', 'BULLET_POINTS']:\n",
    "    data[col] = data[col].apply(lambda x: x.lower())\n",
    "\n",
    "for col in ['DESCRIPTION', 'TITLE', 'BULLET_POINTS']:\n",
    "    data[col] = data[col].apply(lambda x: x.translate(str.maketrans(\"\", \"\", string.punctuation)))\n",
    "    \n",
    "stop = stopwords.words('english')\n",
    "for col in ['DESCRIPTION', 'TITLE', 'BULLET_POINTS']:\n",
    "    data[col] = data[col].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc]\n\u001b[1;32m----> 8\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mTEXT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mTEXT\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: tokenize(x))\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4527\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4528\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4530\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4631\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      5\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc]\n\u001b[1;32m----> 8\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mTEXT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mTEXT\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: tokenize(x))\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(text):\n\u001b[1;32m----> 5\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc]\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:274\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 33\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[0;32m     34\u001b[0m         X,\n\u001b[0;32m     35\u001b[0m         model\u001b[39m.\u001b[39;49mlayers,\n\u001b[0;32m     36\u001b[0m         unseen_classes\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39munseen_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     37\u001b[0m         train\u001b[39m=\u001b[39;49mis_train,\n\u001b[0;32m     38\u001b[0m         has_upper\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mhas_upper\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:213\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\with_array.py:38\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\with_array.py:73\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     71\u001b[0m lengths \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[0;32m     72\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[1;32m---> 73\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[0;32m     76\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\thinc\\layers\\maxout.py:53\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     51\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_param(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m W \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape2f(W, nO \u001b[39m*\u001b[39m nP, nI)\n\u001b[1;32m---> 53\u001b[0m Y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgemm(X, W, trans2\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     54\u001b[0m Y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape1f(b, nO \u001b[39m*\u001b[39m nP)\n\u001b[0;32m     55\u001b[0m Z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mreshape3f(Y, Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nO, nP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "data['TEXT'] = data['TEXT'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arsh0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Tokenizing data: 100%|██████████| 2249698/2249698 [10:24<00:00, 3407.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing data: 100%|██████████| 2249698/2249698 [10:37<00:00, 3407.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model built\n",
      "vocab built\n",
      "model trained\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "batch_size = 1000\n",
    "total = len(data)\n",
    "pbar = tqdm(total=total, desc='Tokenizing data')\n",
    "data_batches = np.array_split(data, len(data) // batch_size)\n",
    "tokenized_data = []\n",
    "for batch in data_batches:\n",
    "    batch['TEXT'] = batch['TEXT'].apply(lambda x: nltk.word_tokenize(x))\n",
    "    tokenized_data.append(batch)\n",
    "    pbar.update(len(batch))\n",
    "print(\"Tokenization complete\")\n",
    "import gensim\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")\n",
    "print(\"model built\")\n",
    "model.build_vocab(data['TEXT'])\n",
    "print(\"vocab built\")\n",
    "model.train(data['TEXT'], total_examples=model.corpus_count, epochs=model.epochs)\n",
    "print(\"model trained\")\n",
    "model.save(\"word2vec.model\")\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review text processed\n",
      "model built\n",
      "model loaded\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n",
      "tulip found\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "review_text = data.TEXT.apply(gensim.utils.simple_preprocess)\n",
    "print(\"review text processed\")\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")\n",
    "print(\"model built\")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec.load('word2vec.model')\n",
    "print(\"model loaded\")\n",
    "# Define a function to transform a list of words into a vector\n",
    "def text_to_vector(text):\n",
    "    vector = np.zeros(w2v_model.vector_size)\n",
    "    num_words = 0\n",
    "    for word in text:\n",
    "        if word in w2v_model.wv:\n",
    "            if word == 'tulip':\n",
    "                print(\"tulip found\")\n",
    "            vector += w2v_model.wv[word]\n",
    "            num_words += 1\n",
    "    if num_words > 0:\n",
    "        vector /= num_words\n",
    "    return vector\n",
    "\n",
    "# Apply the function to your text data to transform it into vectors\n",
    "data['vectors'] = review_text.apply(lambda x: text_to_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('word2vec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Vocab built\n",
      "Model trained\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "model.build_vocab(review_text, progress_per = 1000)\n",
    "print(\"Vocab built\")\n",
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "print(\"Model trained\")\n",
    "model.save(\"word2vec.model\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39msimilar_by_word(\u001b[39m'\u001b[39m\u001b[39mshoes\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.wv.similar_by_word('shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec.load('word2vec.model')\n",
    "# Define a function to transform a list of words into a vector\n",
    "def text_to_vector(text):\n",
    "    vector = np.zeros(w2v_model.vector_size)\n",
    "    num_words = 0\n",
    "    for word in text:\n",
    "        print(word)\n",
    "        print(word in w2v_model.wv)\n",
    "        if word in w2v_model.wv:\n",
    "            print(\"reached\")\n",
    "            vector += w2v_model.wv[word]\n",
    "            num_words += 1\n",
    "    if num_words > 0:\n",
    "        vector /= num_words\n",
    "    return vector\n",
    "\n",
    "# Apply the function to your text data to transform it into vectors\n",
    "data['vectors'] = review_text.apply(lambda x: text_to_vector(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [ 2.76438198  1.03101277  1.43711287  0.188024...\n",
       "1          [ 1.63797701  0.9281052   0.29943667  0.079936...\n",
       "2          [ 0.49348591  1.00943766  2.06150385 -1.536642...\n",
       "3          [ 2.53543026  1.13600364  0.16388655 -0.308092...\n",
       "4          [ 0.81451654  0.24160927 -1.17535807  1.311491...\n",
       "                                 ...                        \n",
       "2249693    [ 1.08165692  0.5752942   0.76280622  0.263596...\n",
       "2249694    [-0.60974843  1.56597216  0.98190239  1.656604...\n",
       "2249695    [ 0.53458225  0.52373439  0.6412862   0.023277...\n",
       "2249696    [-1.10309576 -0.65143969  1.57894686  1.319372...\n",
       "2249697    [-6.39604987e-01 -2.28323179e-01  2.17671043e+...\n",
       "Name: vectors, Length: 2249698, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "def convert_string_to_array(vector_string):\n",
    "    # remove square brackets\n",
    "    vector_string = vector_string[2:-2]\n",
    "    # split string into array of floats\n",
    "    vector_array = np.array([float(num) for num in vector_string.split()])\n",
    "    # reshape array to 2D array with single row\n",
    "    vector_array = vector_array.reshape(1, -1)\n",
    "    # normalize vectors in the array\n",
    "    vector_array = normalize(vector_array)\n",
    "    return vector_array\n",
    "data['vectors'] = data['vectors'].apply(convert_string_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('word2vec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>vectors</th>\n",
       "      <th>vectors_1</th>\n",
       "      <th>vectors_2</th>\n",
       "      <th>vectors_3</th>\n",
       "      <th>vectors_4</th>\n",
       "      <th>vectors_5</th>\n",
       "      <th>vectors_6</th>\n",
       "      <th>vectors_7</th>\n",
       "      <th>vectors_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vectors_91</th>\n",
       "      <th>vectors_92</th>\n",
       "      <th>vectors_93</th>\n",
       "      <th>vectors_94</th>\n",
       "      <th>vectors_95</th>\n",
       "      <th>vectors_96</th>\n",
       "      <th>vectors_97</th>\n",
       "      <th>vectors_98</th>\n",
       "      <th>vectors_99</th>\n",
       "      <th>vectors_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2125.980000</td>\n",
       "      <td>[[0.24486599278792262, 0.09132600607643815, 0....</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>0.021919</td>\n",
       "      <td>-0.048887</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>-0.032069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.035667</td>\n",
       "      <td>0.01725</td>\n",
       "      <td>-0.06078</td>\n",
       "      <td>0.213969</td>\n",
       "      <td>0.110116</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.05306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>393.700000</td>\n",
       "      <td>[[0.12145305302285102, 0.06881733344131842, 0....</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>0.021919</td>\n",
       "      <td>-0.048887</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>-0.032069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.035667</td>\n",
       "      <td>0.01725</td>\n",
       "      <td>-0.06078</td>\n",
       "      <td>0.213969</td>\n",
       "      <td>0.110116</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.05306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>748.031495</td>\n",
       "      <td>[[0.03937756535735372, 0.08054778591515246, 0....</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>0.021919</td>\n",
       "      <td>-0.048887</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>-0.032069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.035667</td>\n",
       "      <td>0.01725</td>\n",
       "      <td>-0.06078</td>\n",
       "      <td>0.213969</td>\n",
       "      <td>0.110116</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.05306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>787.401574</td>\n",
       "      <td>[[0.21314571451127345, 0.09550028307038012, 0....</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>0.021919</td>\n",
       "      <td>-0.048887</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>-0.032069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.035667</td>\n",
       "      <td>0.01725</td>\n",
       "      <td>-0.06078</td>\n",
       "      <td>0.213969</td>\n",
       "      <td>0.110116</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.05306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>598.424000</td>\n",
       "      <td>[[0.07313064166405209, 0.02169267298989804, -0...</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>0.021919</td>\n",
       "      <td>-0.048887</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>-0.032069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.035667</td>\n",
       "      <td>0.01725</td>\n",
       "      <td>-0.06078</td>\n",
       "      <td>0.213969</td>\n",
       "      <td>0.110116</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>-0.05306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_LENGTH                                            vectors   \n",
       "0     2125.980000  [[0.24486599278792262, 0.09132600607643815, 0....  \\\n",
       "1      393.700000  [[0.12145305302285102, 0.06881733344131842, 0....   \n",
       "2      748.031495  [[0.03937756535735372, 0.08054778591515246, 0....   \n",
       "3      787.401574  [[0.21314571451127345, 0.09550028307038012, 0....   \n",
       "4      598.424000  [[0.07313064166405209, 0.02169267298989804, -0...   \n",
       "\n",
       "   vectors_1  vectors_2  vectors_3  vectors_4  vectors_5  vectors_6   \n",
       "0   0.113415   0.036357   0.034459  -0.015105   0.021919  -0.048887  \\\n",
       "1   0.113415   0.036357   0.034459  -0.015105   0.021919  -0.048887   \n",
       "2   0.113415   0.036357   0.034459  -0.015105   0.021919  -0.048887   \n",
       "3   0.113415   0.036357   0.034459  -0.015105   0.021919  -0.048887   \n",
       "4   0.113415   0.036357   0.034459  -0.015105   0.021919  -0.048887   \n",
       "\n",
       "   vectors_7  vectors_8  ...  vectors_91  vectors_92  vectors_93  vectors_94   \n",
       "0  -0.054492  -0.032069  ...   -0.118073   -0.035667     0.01725    -0.06078  \\\n",
       "1  -0.054492  -0.032069  ...   -0.118073   -0.035667     0.01725    -0.06078   \n",
       "2  -0.054492  -0.032069  ...   -0.118073   -0.035667     0.01725    -0.06078   \n",
       "3  -0.054492  -0.032069  ...   -0.118073   -0.035667     0.01725    -0.06078   \n",
       "4  -0.054492  -0.032069  ...   -0.118073   -0.035667     0.01725    -0.06078   \n",
       "\n",
       "   vectors_95  vectors_96  vectors_97  vectors_98  vectors_99  vectors_100  \n",
       "0    0.213969    0.110116   -0.009882   -0.035154    0.009612     -0.05306  \n",
       "1    0.213969    0.110116   -0.009882   -0.035154    0.009612     -0.05306  \n",
       "2    0.213969    0.110116   -0.009882   -0.035154    0.009612     -0.05306  \n",
       "3    0.213969    0.110116   -0.009882   -0.035154    0.009612     -0.05306  \n",
       "4    0.213969    0.110116   -0.009882   -0.035154    0.009612     -0.05306  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparr = np.array(data.vectors.to_list())\n",
    "nparr = nparr.squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24486599,  0.09132601,  0.12729792, ...,  0.04174056,\n",
       "         0.01596737,  0.06698156],\n",
       "       [ 0.12145305,  0.06881733,  0.02220269, ..., -0.02544028,\n",
       "         0.05622753,  0.09478858],\n",
       "       [ 0.03937757,  0.08054779,  0.1644971 , ...,  0.00674603,\n",
       "        -0.1030179 , -0.10387118],\n",
       "       ...,\n",
       "       [ 0.05688426,  0.05572996,  0.0682385 , ..., -0.06855369,\n",
       "        -0.1818304 , -0.08117015],\n",
       "       [-0.08860804, -0.052328  ,  0.12683158, ...,  0.03183769,\n",
       "        -0.20036051, -0.10950936],\n",
       "       [-0.06339921, -0.02263195,  0.21576087, ..., -0.09146177,\n",
       "         0.0636594 , -0.16181896]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanAbsolutePercentageError()])\n\u001b[0;32m     19\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n\u001b[0;32m     22\u001b[0m \u001b[39m# predict on test data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\arsh0\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "with tf.device('/gpu:0'):\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(nparr, data['PRODUCT_LENGTH'], test_size=0.2)\n",
    "\n",
    "    # create a neural network model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # calculate evaluation metric\n",
    "    score = max(0, 100 * (1 - metrics.mean_absolute_percentage_error(y_test, y_pred)))\n",
    "\n",
    "    print('Score:', score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
